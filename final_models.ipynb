{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Researchers: Leo Hu and Natnael Mulat\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "def load_fashion_mnist():\n",
    "    \"\"\"\n",
    "    Loads Fashion MNIST dataset.\n",
    "    \n",
    "    Adapted from: https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "    \"\"\"\n",
    "    TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "    TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'    \n",
    "    TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "    TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "    with gzip.open(TRAIN_LABELS, 'rb') as tr_labels_file, gzip.open(TEST_LABELS, 'rb') as ts_labels_file:\n",
    "        train_labels = np.frombuffer(tr_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "        test_labels = np.frombuffer(ts_labels_file.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(TRAIN_IMAGES, 'rb') as tr_images_file, gzip.open(TEST_IMAGES, 'rb') as ts_images_file:\n",
    "        train_images = np.frombuffer(tr_images_file.read(), dtype=np.uint8, offset=16).reshape(len(train_labels), 784)\n",
    "        test_images = np.frombuffer(ts_images_file.read(), dtype=np.uint8, offset=16).reshape(len(test_labels), 784)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "def pretty_print(image_example):\n",
    "    \"\"\" Pretty prints a Fashion MNIST example.\n",
    "\n",
    "    Parameters:\n",
    "        image_example: a 1x784 numpy array corresponding to the features of\n",
    "                       a single image.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    print(np.array_str(image_example, precision=1, max_line_width=116))\n",
    "def usage_example():\n",
    "    \"\"\" Example of how to load and parse Fashion MNIST data. \"\"\"\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_fashion_mnist()\n",
    "\n",
    "    # train_images is a 60,000 x 784 numpy matrix. There are 60k\n",
    "    # rows in the matrix, each row corresponding to a single example.\n",
    "    # There are 784 columns, each corresponding to the value of a\n",
    "    # single pixel in the 28x28 image after it has been \"flattened\".\n",
    "    print(\"Dimensions of training set feature matrix:\", train_images.shape)\n",
    "    #df = pd.DataFrame()\n",
    "    #print(min(train_labels))\n",
    " \n",
    "\n",
    "    # The labels for each example are maintained separately in train_labels.\n",
    "    # This is a 60,000 x 1 numpy matrix, where each element is the label\n",
    "    # for the corresponding training example.\n",
    "    print(\"Dimensions of training set label matrix:\", train_labels.shape)\n",
    "\n",
    "    # Example of how to access a individual training example (in this case,\n",
    "    # we pick an example at a random index). We could use print to output the\n",
    "    # raw pixel values to the screen, but pretty_print formats the data in \n",
    "    # a nicer way: if you squint, you may be able to make out the contours of\n",
    "    # the fashion article in the matrix data.\n",
    "    EXAMPLE_INDEX = np.random.randint(60000)\n",
    "    print(\"Features of training example at index {}:\\n\".format(EXAMPLE_INDEX))\n",
    "    pretty_print(train_images[EXAMPLE_INDEX])\n",
    "\n",
    "    # And here's the label that goes with that training example\n",
    "    print(\"\\nLabel of training example at index {}:\".format(EXAMPLE_INDEX), train_labels[EXAMPLE_INDEX], '\\n')\n",
    "\n",
    "    # Finally, let's visualize the example we've picked as a 28x28 image\n",
    "    plt.figure()\n",
    "    plt.imshow(train_images[EXAMPLE_INDEX].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    # The test_images/test_labels are organized in the same way, but only contain 10k\n",
    "    # examples. Don't touch this data until your model is frozen! Perform all\n",
    "    # cross-validation, model selection, hyperparameter tuning etc. on the 60k\n",
    "    # training set. Use the test set simply for reporting performance.\n",
    "def summarize(y_test, y_pred, avg_method='weighted'):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(\"Test data count: \", len(y_test))\n",
    "    print(\"accuracy_count: \", num_acc)\n",
    "    print(\"accuracy_score: \", acc)\n",
    "    print(\"precision_score: \", prec)\n",
    "    print(\"recall_score\", recall)\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = load_fashion_mnist()\n",
    "x_train, x_valid, train_labels, y_valid = train_test_split(train_images, train_labels, test_size=0.2,random_state=42)\n",
    "\n",
    "train_images = x_train.astype('float32')\n",
    "valid_images = x_valid.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "train_images /= 255\n",
    "valid_images /= 255\n",
    "test_images /= 255\n",
    "\n",
    "print(train_images.shape)\n",
    "print(valid_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# with n_components=0.95, in the reduced dataset (X_train_reduced) we got only 187 features (out of original 784)\n",
    "# , and there was significant loss of information (quality) in the 'recovered' (decompressed) images.\n",
    "# Hence, I have selected n_components=0.99, which gives 458 features (out of original 784) \n",
    "# and there is no significant loss of information (quality) in the 'recovered' images \n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(train_images)\n",
    "\n",
    "\n",
    "\n",
    "pca.n_components_\n",
    "X_train_recovered = pca.inverse_transform(X_train_reduced)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "# Plotting 'original' image\n",
    "plot_digits(train_images[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "# Plotting the corresponding 'recovered' image\n",
    "plot_digits(X_train_recovered[::2100])\n",
    "plt.title(\"Compressed\", fontsize=16)\n",
    "N = 1.75\n",
    "params = plt.gcf()\n",
    "plSize = params.get_size_inches()\n",
    "params.set_size_inches( (plSize[0]*N, plSize[1]*N) )\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,4));\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[2200].reshape(28, 28))\n",
    "plt.title(\"Original Image\", fontsize = 14);\n",
    "plt.xlabel(\"784 components\", fontsize = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_train_recovered[2200].reshape(28, 28))\n",
    "plt.title(\"PCA Inverse-Transformed Image\", fontsize = 14);\n",
    "plt.xlabel(\"458 components\", fontsize = 14)\n",
    "plt.savefig('pca.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=1800, solver='lbfgs')\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='sag', max_iter=1800)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=1800, solver='lbfgs', C=0.5)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=1800, solver='lbfgs', C=0.1)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='sag',C=0.1)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='sag',C=0.5)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='sag',C=0.05)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "acc_list = []\n",
    "f1_score1 = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=i,p=2)\n",
    "    \n",
    "    knn_clf.fit(X_train_reduced, train_labels)\n",
    "    \n",
    "    X_valid_reduced = pca.transform(valid_images)\n",
    "    \n",
    "    prediction = knn_clf.predict(X_valid_reduced)\n",
    "    \n",
    "    accuracy = accuracy_score(y_valid, prediction)\n",
    "    \n",
    "    f1 = f1_score(y_valid, prediction, average='micro')\n",
    "    \n",
    "    f1_score1.append((f1,i)) \n",
    "    \n",
    "    acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_k = np.arange(50)\n",
    "plt.figure(dpi=100)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(num_k, acc_list)\n",
    "plt.xlabel('Number of Neihgbors')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.savefig('acc_plotp2.png')\n",
    "print(max(acc_list), max(f1_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "acc_list = []\n",
    "f1_score1 = []\n",
    "\n",
    "for i in range(1, 51):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=i,p=1)\n",
    "    \n",
    "    knn_clf.fit(X_train_reduced, train_labels)\n",
    "    \n",
    "    X_valid_reduced = pca.transform(valid_images)\n",
    "    \n",
    "    prediction = knn_clf.predict(X_valid_reduced)\n",
    "    \n",
    "    accuracy = accuracy_score(y_valid, prediction)\n",
    "    \n",
    "    f1 = f1_score(y_valid, prediction, average='micro')\n",
    "    \n",
    "    f1_score1.append((f1,i)) \n",
    "    \n",
    "    acc_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_k = np.arange(50)\n",
    "plt.figure(dpi=100)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(num_k, acc_list)\n",
    "plt.xlabel('Number of Neihgbors')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.savefig('acc_plotp1.png')\n",
    "print(max(acc_list), max(f1_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='saga',C=0.1,penalty='l1', max_iter=1800)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='saga',C=0.05,penalty='l1', max_iter=1800)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='saga',C=0.5,penalty='l1', max_iter=1800)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='saga',C=1,penalty='l1', max_iter=1800)\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=1800, solver='saga',penalty='l1')\n",
    "logisticRegr.fit(X_train_reduced, train_labels)\n",
    "X_valid_reduced = pca.transform(valid_images)\n",
    "predictions = logisticRegr.predict(X_valid_reduced)\n",
    "\n",
    "print(predictions)\n",
    "summarize(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "y_predicted = [random.randint(0, 9) for p in range(0, len(test_labels))]\n",
    "summarize(test_labels,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "knn_clf.fit(train_images, train_labels)\n",
    "\n",
    "prediction = knn_clf.predict(test_images)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, prediction)\n",
    "\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, class_, title='Confusion matrix', cmap=plt.cm.viridis):\n",
    "    \"\"\"\n",
    "    This function plots a confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(cm, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(class_))\n",
    "    plt.xticks(tick_marks, class_, rotation=90)\n",
    "    plt.yticks(tick_marks, class_)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i,j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"black\" if cm[i, j] > thresh else \"white\")\n",
    "\n",
    "    plt.ylabel('True labels')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.savefig('cm1.png')\n",
    "    N = 1.75\n",
    "    params = plt.gcf()\n",
    "    plSize = params.get_size_inches()\n",
    "    params.set_size_inches( (plSize[0]*N, plSize[1]*N) )\n",
    "    plt.savefig('cm.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_classes     = {0: 'T-shirt/top', \n",
    "                       1: 'Trouser', \n",
    "                       2: 'Pullover', \n",
    "                       3: 'Dress', \n",
    "                       4: 'Coat',\n",
    "                       5: 'Sandal', \n",
    "                       6: 'Shirt', \n",
    "                       7: 'Sneaker', \n",
    "                       8: 'Bag', \n",
    "                       9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(test_labels, prediction), list(fashion_classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
